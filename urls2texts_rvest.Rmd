---
title: "Scrape webpage texts from URLs"
author: "Bin Chen <br /> University of Texas at Austin <br /> bin.chen@utexas.edu"
date: "1/26/2022"
output: html_document
---

```{r}
library(tidyverse)
library(rvest)
library(purrr)
```

```{r}
df <- read_csv("data/ukraine-all-story-urls-20220126173600.csv") %>%
  subset (media_name == "ABC News")
```


# Scrape single article (ABC News)

```{r}
webpage <- read_html(df$url[3])
```

```{r}
title <- webpage %>% 
  html_elements(".Article__Headline__Title") %>% 
  html_text()

body <- webpage %>%
  html_elements("p") %>% 
  html_text() %>%
  str_replace_all("\n", "") %>%
  paste(collapse = " ") 

output1 <- data.frame (url=df$url[3], title = title, body = body)
```


```{r}
print(output1)
```


# Scrape multiple URLs (ABC News)

```{r}
parse <- function(x){
  Sys.sleep(1)
  
  title <- as.character(x) %>% 
    read_html() %>%
    html_elements(".Article__Headline__Title") %>% 
    html_text()
  
  body <-  as.character(x) %>% 
    read_html() %>%
    html_elements("p") %>% 
    html_text() %>%
    str_replace_all("\n", "") %>%
    paste(collapse = " ") 
  
  data.frame(
    url = as.character(x),
    title = title,
    text = body)
}

output2 <- lapply(df$url[1:3], parse) %>% 
  bind_rows()
```


```{r}
print(output2)
```
# Combine datasets
```{r}
all <- left_join(df, output2, by = "url")
```

